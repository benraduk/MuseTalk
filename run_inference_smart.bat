@echo off
REM MuseTalk SMART Inference - Coordinate Caching + Optimized Batching
REM First run: Slow face detection, saves coordinates
REM Subsequent runs: Skip face detection, use cached coordinates = MUCH faster

echo ğŸ§  MuseTalk SMART Inference (Coordinate Caching Strategy)
echo ğŸ“ Working directory: %CD%
echo ğŸ’¡ Strategy: Cache face detection results for instant re-runs
echo ============================================================

REM Set PYTHONPATH to include current directory
set PYTHONPATH=%PYTHONPATH%;%CD%

REM Activate conda environment if not already active
if not "%CONDA_DEFAULT_ENV%"=="musetalk" (
    echo ğŸ”„ Activating musetalk environment...
    call conda activate musetalk
)

REM Check if coordinates already exist
set VIDEO_NAME=Canva_en
if exist "results\%VIDEO_NAME%.pkl" (
    echo ğŸ’¾ Found cached coordinates! Skipping face detection...
    echo âš¡ This run will be MUCH faster!
    python scripts/inference.py --inference_config configs/inference/test.yaml --unet_config ./models/musetalkV15/musetalk.json --batch_size 16 --use_saved_coord
) else (
    echo ğŸ” First run: Will perform face detection and cache results
    echo â³ This will take ~4 minutes, but future runs will be instant!
    python scripts/inference.py --inference_config configs/inference/test.yaml --unet_config ./models/musetalkV15/musetalk.json --batch_size 16
    echo ğŸ’¾ Coordinates cached for future runs!
)

echo ============================================================
echo âœ… Smart inference completed!
