graph TD
    %% DEPENDENCY TREE - SURGICAL INTEGRATION
    
    %% INPUT LAYER
    A[Input: Video + Audio] --> B[scripts/inference.py]
    
    %% PREPROCESSING DEPENDENCIES
    B --> C[Face Detection Module]
    B --> D[Audio Processing Module]
    
    %% Face Detection Dependencies (MUSETALK - KEEP)
    C --> C1["musetalk/utils/face_detection/<br/>🟢 FaceAlignment, LandmarksType"]
    C1 --> C1a["Dependencies:<br/>• torch<br/>• opencv-python<br/>• numpy"]
    
    C --> C2["musetalk/utils/preprocessing/<br/>🟢 get_landmark_and_bbox_enhanced()"]
    C2 --> C2a["Dependencies:<br/>• torch<br/>• numpy<br/>• cv2"]
    
    %% Audio Processing Dependencies (MUSETALK - KEEP)
    D --> D1["musetalk/whisper/<br/>🟢 WhisperModel"]
    D1 --> D1a["Dependencies:<br/>• transformers==4.48.0<br/>• torch==2.2.0<br/>• librosa==0.11.0"]
    
    %% DATA GENERATION DEPENDENCIES (MUSETALK ENHANCED)
    B --> E[Data Generation Module]
    E --> E1["musetalk/utils/utils/<br/>🟢 datagen_enhanced()"]
    E1 --> E1a["Dependencies:<br/>• torch<br/>• numpy<br/>• itertools"]
    
    %% VAE ENCODING DEPENDENCIES (MUSETALK - KEEP)
    B --> F[VAE Encoding Module]
    F --> F1["musetalk/models/vae/<br/>🟢 VAE.encode()"]
    F1 --> F1a["Dependencies:<br/>• diffusers==0.32.2<br/>• torch==2.2.0"]
    
    %% SURGICAL INFERENCE POINT
    B --> G["🔄 SURGICAL POINT:<br/>UNet Inference"]
    
    %% MuseTalk UNet (FALLBACK)
    G --> G1["musetalk/models/unet/<br/>🟡 UNet.model() - FALLBACK"]
    G1 --> G1a["Dependencies:<br/>• torch==2.2.0<br/>• diffusers (old version)"]
    
    %% LatentSync UNet3D (PRIMARY)
    G --> G2["LatentSync/latentsync/models/unet/<br/>🔴 UNet3DConditionModel - PRIMARY"]
    G2 --> G2a["Dependencies:<br/>• diffusers==0.32.2<br/>• torch==2.2.0<br/>• einops"]
    
    %% Surgical Wrapper (NEW)
    G --> G3["scripts/hybrid_inference.py<br/>🆕 surgical_unet3d_inference()"]
    G3 --> G3a["Dependencies:<br/>• torch==2.2.0<br/>• diffusers==0.32.2<br/>• Both UNet models"]
    
    %% VAE DECODING (MUSETALK - KEEP)
    B --> H[VAE Decoding Module]
    H --> H1["musetalk/models/vae/<br/>🟢 VAE.decode_latents()"]
    H1 --> H1a["Dependencies:<br/>• diffusers==0.32.2<br/>• torch==2.2.0"]
    
    %% FRAME BLENDING (MUSETALK ENHANCED)
    B --> I[Frame Blending Module]
    I --> I1["musetalk/utils/blending/<br/>🟢 get_image()"]
    I1 --> I1a["Dependencies:<br/>• opencv-python<br/>• numpy"]
    
    %% OUTPUT
    B --> J[Video Output]
    J --> J1["Dependencies:<br/>• opencv-python<br/>• ffmpeg-python"]
    
    %% ELIMINATED DEPENDENCIES (SHOWN FOR CONTEXT)
    K["❌ ELIMINATED CONFLICTS"]
    K --> K1["mmpose, mmcv, mmdet<br/>(MMLab ecosystem)"]
    K --> K2["tensorflow, tensorboard<br/>(Training dependencies)"]
    K --> K3["insightface, mediapipe<br/>(LatentSync preprocessing)"]
    K --> K4["onnxruntime-gpu, face-alignment<br/>(Redundant components)"]
    
    %% STYLING
    classDef keep fill:#90EE90,stroke:#006400,stroke-width:2px
    classDef surgical fill:#FFB6C1,stroke:#DC143C,stroke-width:2px
    classDef new fill:#87CEEB,stroke:#4682B4,stroke-width:2px
    classDef eliminated fill:#FFCCCB,stroke:#8B0000,stroke-width:2px
    classDef fallback fill:#FFF8DC,stroke:#DAA520,stroke-width:2px
    
    class C1,C2,D1,E1,F1,H1,I1 keep
    class G2,G2a surgical
    class G3,G3a new
    class K,K1,K2,K3,K4 eliminated
    class G1,G1a fallback